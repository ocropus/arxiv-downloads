{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import msgpack as mp\n",
    "import tempfile\n",
    "from itertools import islice\n",
    "import sys\n",
    "\n",
    "os.environ[\"WDS_CACHE\"] = \"/work/cache\"\n",
    "os.environ[\"WDS_VERBOSE_CACHE\"] = \"1\"\n",
    "os.environ[\"GOPEN_VERBOSE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(fname):\n",
    "    prefix, suffix = fname.rsplit(\".\", 1)\n",
    "    prefix = re.sub(\"[.]\", \",\", prefix)\n",
    "    return prefix + \".\" + suffix\n",
    "\n",
    "ds = wds.WebDataset(\"pipe:gsutil cp gs://ocro-arxiv/pdfs/arxiv-pdfs-{000000..001038}.tar /tmp/$$.tar && cat /tmp/$$.tar && rm -f /tmp/$$.tar\", rename_files=rename_files)\n",
    "ds = wds.WebDataset(\"gs://ocro-arxiv/pdfs/arxiv-pdfs-{000000..001038}.tar\", rename_files=rename_files)\n",
    "pdfsample = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in pdfsample.items():\n",
    "    print(k, repr(v)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShellError(Exception):\n",
    "    def __init__(self, status, *args):\n",
    "        super().__init__(*args)\n",
    "        self.status = status\n",
    "\n",
    "def run(x):\n",
    "    # print(\"#\", x, file=sys.stderr)\n",
    "    status = os.system(x)\n",
    "    if status != 0:\n",
    "        raise ShellError(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bin(fname):\n",
    "    with open(fname, \"rb\") as stream:\n",
    "        return stream.read()\n",
    "\n",
    "def expand_pdf(data, prefix):\n",
    "    tdir = \"temp\"\n",
    "    dpi = 300\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tdir:\n",
    "        with open(f\"{tdir}/doc.pdf\", \"wb\") as stream:\n",
    "            stream.write(data)\n",
    "\n",
    "        run(f\"cd {tdir} && pdftk doc.pdf burst\")\n",
    "\n",
    "        pages = sorted(glob.glob(tdir+\"/pg_????.pdf\"))\n",
    "\n",
    "        for pg in pages:\n",
    "            base = pg[:-4]\n",
    "            assert os.system(f\"pdftoppm -r {dpi} -jpeg {pg} -singlefile -jpegopt quality=95 -o {base}\") == 0\n",
    "\n",
    "        for pg in pages:\n",
    "            base = pg[:-4]\n",
    "            run(f\"pdftoppm -r {dpi} -jpeg {pg} -singlefile -jpegopt quality=100 -o {base}\")    \n",
    "\n",
    "        for pg in pages:\n",
    "            base = pg[:-4]\n",
    "            run(f\"pdftotext {pg}\")\n",
    "\n",
    "        for pg in pages:\n",
    "            base = pg[:-4]\n",
    "            run(f\"pdftotree {pg} > {base}.temp && mv {base}.temp {base}.hocr\")\n",
    "\n",
    "        for pageno, hocr in enumerate(sorted(glob.glob(tdir+\"/*.hocr\"))):\n",
    "            base = hocr[:-5]\n",
    "            sample = dict(\n",
    "                __key__=f\"{prefix}/{pageno}\",\n",
    "                hocr=read_bin(hocr),\n",
    "                txt=read_bin(base+\".txt\"),\n",
    "                pdf=read_bin(base+\".pdf\"),\n",
    "                jpg=read_bin(base+\".jpg\")\n",
    "            )\n",
    "            yield sample\n",
    "\n",
    "result = list(expand_pdf(pdfsample[\"pdf\"], pdfsample[\"__key__\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for k, v in result[0].items():\n",
    "        print(k, repr(v)[:50])\n",
    "    print(result[0][\"hocr\"].decode(\"utf-8\"))\n",
    "    print(result[0][\"txt\"].decode(\"utf-8\"))\n",
    "    import io\n",
    "    from imageio import imread\n",
    "    image = imread(io.BytesIO(result[0][\"jpg\"]))\n",
    "    imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_expand_pdfs(ds):\n",
    "    for pdfsample in ds:\n",
    "        key = pdfsample[\"__key__\"]\n",
    "        print(\"***\", key)\n",
    "        try:\n",
    "            for sample in expand_pdf(pdfsample[\"pdf\"], pdfsample[\"__key__\"]):\n",
    "                yield sample\n",
    "        except ShellError as exn:\n",
    "            print(f\"{key}: shell error {exn.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile _\n",
    "expanded = ds.compose(map_expand_pdfs)\n",
    "dl = wds.WebLoader(expanded, num_workers=8, batch_size=None).shuffle(5000)\n",
    "destination = \"gs://ocro-arxiv/hocr\"\n",
    "def upload(fname):\n",
    "    run(f\"sync; sleep 1; gsutil --quiet -m cp {fname} {destination}/{fname}\")\n",
    "    os.unlink(fname)\n",
    "sink = wds.ShardWriter(\"arxiv-hocr-%06d.tar\", maxcount=300, maxsize=500e6, post=upload, encoder=None)\n",
    "for sample in dl:\n",
    "    sink.write(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsexists(gspath):\n",
    "    assert gspath.startswith(\"gs://\")\n",
    "    return os.system(f\"gsutil ls {gspath} > /dev/null\") == 0\n",
    "\n",
    "def upload(fname, gspath):\n",
    "    run(f\"sync; sleep 1; gsutil --quiet -m cp {fname} {gspath}\")\n",
    "    os.unlink(fname)\n",
    "\n",
    "def process_shard(shardno):\n",
    "    fname = f\"arxiv-hocr-{shardno:06d}.tar\"\n",
    "    destination = \"gs://ocro-arxiv/hocr\"\n",
    "    gspath = f\"{destination}/{fname}\"\n",
    "    if gsexists(gspath):\n",
    "        print(f\"EXISTS: {gspath}\")\n",
    "        return\n",
    "    sname = f\"gs://ocro-arxiv/pdfs/arxiv-pdfs-{shardno:06d}.tar\"\n",
    "    print(\"converting\", sname, \"->\", gspath)\n",
    "    ds = wds.WebDataset(sname, rename_files=rename_files)\n",
    "    expanded = ds.compose(map_expand_pdfs).shuffle(1000)\n",
    "    sink = wds.TarWriter(fname, encoder=None)\n",
    "    for sample in ds:\n",
    "        sink.write(sample)\n",
    "    sink.close()\n",
    "    upload(fname, gspath)\n",
    "\n",
    "process_shard(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init(num_cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [ray.remote(num_cpus=2)(process_shard).remote(i) for i in range(0, 1039)]\n",
    "results2 = ray.get(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
